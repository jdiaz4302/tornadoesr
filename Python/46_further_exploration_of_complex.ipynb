{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration of Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 hidden layers was a dud, 70 showed promise, so here we go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pylab\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "tor_df = pd.read_csv(\"/home/jeremy/github_tornadoesr/data/raw/tor_train_set_no_zeros_mob_home.csv\")\n",
    "\n",
    "\n",
    "# Quick inspection\n",
    "tor_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Seperating variables\n",
    "# The dependent variables\n",
    "tornado_outcomes = tor_df.iloc[:, [0]]\n",
    "\n",
    "\n",
    "# Quick inspection\n",
    "tornado_outcomes.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The independent variables\n",
    "tornado_features = tor_df.iloc[:, 1:]\n",
    "\n",
    "\n",
    "# Quick inspection\n",
    "tornado_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the dependent variables into a numpy array\n",
    "outcomes_array = tornado_outcomes.values\n",
    "\n",
    "\n",
    "# Makes the numpy array into a torch Tensor\n",
    "outcomes_Tensor = torch.from_numpy(outcomes_array)\n",
    "\n",
    "\n",
    "# Quick inspection\n",
    "outcomes_Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the independent variables into a numpy array\n",
    "features_array = tornado_features.values\n",
    "\n",
    "\n",
    "# Make the numpy array into a torch Tensor\n",
    "features_Tensor = torch.from_numpy(features_array)\n",
    "\n",
    "\n",
    "# Quick inspection\n",
    "features_Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert DoubleTensor to FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Changing dependent variables from a DoubleTensor to a FloatTensor\n",
    "outcomes_Tensor = outcomes_Tensor.float()\n",
    "\n",
    "\n",
    "# ...and for the independent variables\n",
    "features_Tensor = features_Tensor.float()\n",
    "\n",
    "\n",
    "# Quick check\n",
    "features_Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1: Seventy Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the torch Tensor into a PyTorch Variable for dependent variables\n",
    "outcomes_Variable = Variable(outcomes_Tensor)\n",
    "\n",
    "\n",
    "# ...for independent variables\n",
    "features_Variable = Variable(features_Tensor,\n",
    "                             requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make the neural network\n",
    "model = torch.nn.Sequential(torch.nn.Linear(32, 32),    # Hidden Layer (HL) 1\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 2\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 3\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 4\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 5\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 6\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 7\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 8\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 9\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 10\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 11\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 12\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 13\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 14\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 15\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 16\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 17\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 18\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 19\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 20\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 21\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 22\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 23\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 24\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 25\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 26\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 27\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 28\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 29\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 30\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 31\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 32\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 33\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 34\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 35\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 36\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 37\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 38\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 39\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 40\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 41\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 42\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 43\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 44\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 45\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 46\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 47\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 48\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 49\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 50\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 51\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 52\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 53\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 54\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 55\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 56\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 57\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 58\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 59\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 60\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 61\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 62\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 63\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 64\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 65\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 66\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 67\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 68\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 69\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 70\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the loss function\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To add errors to\n",
    "errors = []\n",
    "\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 2e-3\n",
    "\n",
    "\n",
    "# Define the model's optimizer\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Train the neural network\n",
    "for t in range(15000):\n",
    "    \n",
    "    # Get the current predictions\n",
    "    y_pred = model(features_Variable)\n",
    "    \n",
    "    # Compute and append current summed errors\n",
    "    loss = loss_fn(y_pred, outcomes_Variable)\n",
    "    errors.append(loss.data[0])\n",
    "    \n",
    "    # Zero the gradients before running the backward pass.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable Variables\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights using Adagrad\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the iterations\n",
    "iterations = list(range(0, 15000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot summed error as a function of iteration\n",
    "plt.scatter(iterations, errors, c = \"black\", alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_pred_resized = y_pred.resize(8230)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_pred_array = y_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_pred_list = y_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "outcomes_Variable_resized = outcomes_Variable.resize(8230)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "outcomes_array = outcomes_Variable_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "outcomes_list = outcomes_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot predictions versus training set outcomes\n",
    "plt.scatter(outcomes_list, y_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([-2, 4])\n",
    "\n",
    "axes.set_ylim([-2, 4])\n",
    "\n",
    "plt.plot([-2, 4], [-2, 4], 'k-', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "valid_df = pd.read_csv(\"/home/jeremy/github_tornadoesr/data/raw/tor_cv_set_no_zeros_mob_home.csv\")\n",
    "\n",
    "\n",
    "# Validation set outcomes\n",
    "valid_outcomes = valid_df.iloc[:, [0]]\n",
    "\n",
    "\n",
    "# Make the validation outcomes into a numpy array\n",
    "valid_outcomes_array = valid_outcomes.values\n",
    "\n",
    "\n",
    "# Makes the numpy array into a torch Tensor\n",
    "valid_outcomes_Tensor = torch.from_numpy(valid_outcomes_array)\n",
    "\n",
    "\n",
    "# Changing validation outcomes from a DoubleTensor to a FloatTensor\n",
    "valid_outcomes_Tensor = valid_outcomes_Tensor.float()\n",
    "\n",
    "\n",
    "# Make the Tensor into a Pytorch Variable\n",
    "valid_outcomes_Variable = Variable(valid_outcomes_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Validation set predictors\n",
    "valid_predictors = valid_df.iloc[:, 1:]\n",
    "\n",
    "\n",
    "# Make the validation predictors into a numpy array\n",
    "valid_predictors_array = valid_predictors.values\n",
    "\n",
    "\n",
    "# Makes the numpy array into a torch Tensor\n",
    "valid_predictors_Tensor = torch.from_numpy(valid_predictors_array)\n",
    "\n",
    "\n",
    "# Changing validation predictors from a DoubleTensor to a FloatTensor\n",
    "valid_predictors_Tensor = valid_predictors_Tensor.float()\n",
    "\n",
    "\n",
    "# Make the Tensor into a Pytorch Variable\n",
    "valid_predictors_Variable = Variable(valid_predictors_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the validation set predictions\n",
    "y_valid_pred = model(valid_predictors_Variable)\n",
    "\n",
    "\n",
    "# Print the loss\n",
    "loss_fn(y_valid_pred,\n",
    "        valid_outcomes_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_valid_pred_resized = y_valid_pred.resize(2748)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_valid_pred_array = y_valid_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_valid_pred_list = y_valid_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "valid_outcomes_Variable_resized = valid_outcomes_Variable.resize(2748)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "valid_outcomes_array = valid_outcomes_Variable_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "valid_outcomes_list = valid_outcomes_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot new predictions versus new data outcomes\n",
    "plt.scatter(valid_outcomes_list, y_valid_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([-2, 4])\n",
    "\n",
    "axes.set_ylim([-2, 4])\n",
    "\n",
    "plt.plot([-2, 4], [-2, 4], 'k-', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "test_df = pd.read_csv(\"/home/jeremy/github_tornadoesr/data/raw/tor_test_set_no_zeros_mob_home.csv\")\n",
    "\n",
    "\n",
    "# Validation set outcomes\n",
    "test_outcomes = test_df.iloc[:, [0]]\n",
    "\n",
    "\n",
    "# Make the validation outcomes into a numpy array\n",
    "test_outcomes_array = test_outcomes.values\n",
    "\n",
    "\n",
    "# Makes the numpy array into a torch Tensor\n",
    "test_outcomes_Tensor = torch.from_numpy(test_outcomes_array)\n",
    "\n",
    "\n",
    "# Changing validation outcomes from a DoubleTensor to a FloatTensor\n",
    "test_outcomes_Tensor = test_outcomes_Tensor.float()\n",
    "\n",
    "\n",
    "# Make the Tensor into a Pytorch Variable\n",
    "test_outcomes_Variable = Variable(test_outcomes_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation set predictors\n",
    "test_predictors = test_df.iloc[:, 1:]\n",
    "\n",
    "\n",
    "# Make the validation predictors into a numpy array\n",
    "test_predictors_array = test_predictors.values\n",
    "\n",
    "\n",
    "# Makes the numpy array into a torch Tensor\n",
    "test_predictors_Tensor = torch.from_numpy(test_predictors_array)\n",
    "\n",
    "\n",
    "# Changing validation predictors from a DoubleTensor to a FloatTensor\n",
    "test_predictors_Tensor = test_predictors_Tensor.float()\n",
    "\n",
    "\n",
    "# Make the Tensor into a Pytorch Variable\n",
    "test_predictors_Variable = Variable(test_predictors_Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the validation set predictions\n",
    "y_test_pred = model(test_predictors_Variable)\n",
    "\n",
    "\n",
    "# Print the loss\n",
    "loss_fn(y_test_pred,\n",
    "        test_outcomes_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_test_pred_resized = y_test_pred.resize(2699)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_test_pred_array = y_test_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Convert back to native units and scale\n",
    "y_test_pred_array = y_test_pred_array*5.41747 + 7.67485\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_test_pred_list = y_test_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "test_outcomes_Variable_resized = test_outcomes_Variable.resize(2699)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "test_outcomes_array = test_outcomes_Variable_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Convert back to native units and scale\n",
    "test_outcomes_array = test_outcomes_array*5.41747 + 7.67485\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "test_outcomes_list = test_outcomes_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot new predictions versus new data outcomes\n",
    "plt.scatter(test_outcomes_list, y_test_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([2, 23])\n",
    "\n",
    "axes.set_ylim([2, 23])\n",
    "\n",
    "axes.set_xticks([2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "axes.set_yticks([2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "plt.plot([2, 23], [2, 23], 'k-', lw=2)\n",
    "\n",
    "axes.set_xlabel(\"Actual Outcome (Log-Transformed US Dollars)\")\n",
    "\n",
    "axes.set_ylabel(\"Model Prediction (Log-Transformed US Dollars)\")\n",
    "\n",
    "axes.set_title(\"Model Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Seventy Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the torch Tensor into a PyTorch Variable for dependent variables\n",
    "outcomes_Variable = Variable(outcomes_Tensor)\n",
    "\n",
    "\n",
    "# ...for independent variables\n",
    "features_Variable = Variable(features_Tensor,\n",
    "                             requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the neural network\n",
    "model = torch.nn.Sequential(torch.nn.Linear(32, 32),    # Hidden Layer (HL) 1\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 2\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 3\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 4\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 5\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 6\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 7\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 8\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 9\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 10\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 11\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 12\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 13\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 14\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 15\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 16\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 17\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 18\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 19\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 20\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 21\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 22\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 23\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 24\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 25\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 26\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 27\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 28\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 29\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 30\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 31\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 32\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 33\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 34\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 35\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 36\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 37\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 38\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 39\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 40\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 41\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 42\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 43\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 44\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 45\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 46\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 47\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 48\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 49\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 50\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 51\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 52\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 53\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 54\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 55\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 56\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 57\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 58\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 59\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 60\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 61\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 62\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 63\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 64\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 65\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 66\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 67\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 68\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 69\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 70\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To add errors to\n",
    "errors = []\n",
    "\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 2e-3\n",
    "\n",
    "\n",
    "# Define the model's optimizer\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Train the neural network\n",
    "for t in range(15000):\n",
    "    \n",
    "    # Get the current predictions\n",
    "    y_pred = model(features_Variable)\n",
    "    \n",
    "    # Compute and append current summed errors\n",
    "    loss = loss_fn(y_pred, outcomes_Variable)\n",
    "    errors.append(loss.data[0])\n",
    "    \n",
    "    # Zero the gradients before running the backward pass.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable Variables\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights using Adagrad\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot summed error as a function of iteration\n",
    "plt.scatter(iterations, errors, c = \"black\", alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_pred_resized = y_pred.resize(8230)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_pred_array = y_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_pred_list = y_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot predictions versus training set outcomes\n",
    "plt.scatter(outcomes_list, y_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([-2, 4])\n",
    "\n",
    "axes.set_ylim([-2, 4])\n",
    "\n",
    "plt.plot([-2, 4], [-2, 4], 'k-', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the validation set predictions\n",
    "y_valid_pred = model(valid_predictors_Variable)\n",
    "\n",
    "\n",
    "# Print the loss\n",
    "loss_fn(y_valid_pred,\n",
    "        valid_outcomes_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_valid_pred_resized = y_valid_pred.resize(2748)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_valid_pred_array = y_valid_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_valid_pred_list = y_valid_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot new predictions versus new data outcomes\n",
    "plt.scatter(valid_outcomes_list, y_valid_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([-2, 4])\n",
    "\n",
    "axes.set_ylim([-2, 4])\n",
    "\n",
    "plt.plot([-2, 4], [-2, 4], 'k-', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the validation set predictions\n",
    "y_test_pred = model(test_predictors_Variable)\n",
    "\n",
    "\n",
    "# Print the loss\n",
    "loss_fn(y_test_pred,\n",
    "        test_outcomes_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_test_pred_resized = y_test_pred.resize(2699)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_test_pred_array = y_test_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Convert back to native units and scale\n",
    "y_test_pred_array = y_test_pred_array*5.41747 + 7.67485\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_test_pred_list = y_test_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot new predictions versus new data outcomes\n",
    "plt.scatter(test_outcomes_list, y_test_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([2, 23])\n",
    "\n",
    "axes.set_ylim([2, 23])\n",
    "\n",
    "axes.set_xticks([2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "axes.set_yticks([2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "plt.plot([2, 23], [2, 23], 'k-', lw=2)\n",
    "\n",
    "axes.set_xlabel(\"Actual Outcome (Log-Transformed US Dollars)\")\n",
    "\n",
    "axes.set_ylabel(\"Model Prediction (Log-Transformed US Dollars)\")\n",
    "\n",
    "axes.set_title(\"Model Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: One Hundred Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the torch Tensor into a PyTorch Variable for dependent variables\n",
    "outcomes_Variable = Variable(outcomes_Tensor)\n",
    "\n",
    "\n",
    "# ...for independent variables\n",
    "features_Variable = Variable(features_Tensor,\n",
    "                             requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the neural network\n",
    "model = torch.nn.Sequential(torch.nn.Linear(32, 32),    # Hidden Layer (HL) 1\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 2\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 3\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 4\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 5\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 6\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 7\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 8\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 9\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 10\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 11\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 12\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 13\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 14\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 15\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 16\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 17\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 18\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 19\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 20\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 21\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 22\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 23\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 24\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 25\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 26\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 27\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 28\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 29\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 30\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 31\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 32\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 33\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 34\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 35\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 36\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 37\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 38\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 39\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 40\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 41\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 42\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 43\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 44\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 45\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 46\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 47\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 48\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 49\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 50\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 51\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 52\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 53\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 54\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 55\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 56\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 57\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 58\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 59\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 60\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 61\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 62\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 63\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 64\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 65\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 66\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 67\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 68\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 69\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 70\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 71\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 72\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 73\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 74\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 75\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 76\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 77\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 78\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 79\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 80\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 81\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 82\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 83\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 84\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 85\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 86\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 87\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 88\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 89\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 90\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 91\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 92\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 93\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 94\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 95\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 96\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 97\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 98\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 99\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 100\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To add errors to\n",
    "errors = []\n",
    "\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 2e-3\n",
    "\n",
    "\n",
    "# Define the model's optimizer\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Train the neural network\n",
    "for t in range(15000):\n",
    "    \n",
    "    # Get the current predictions\n",
    "    y_pred = model(features_Variable)\n",
    "    \n",
    "    # Compute and append current summed errors\n",
    "    loss = loss_fn(y_pred, outcomes_Variable)\n",
    "    errors.append(loss.data[0])\n",
    "    \n",
    "    # Zero the gradients before running the backward pass.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable Variables\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights using Adagrad\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot summed error as a function of iteration\n",
    "plt.scatter(iterations, errors, c = \"black\", alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_pred_resized = y_pred.resize(8230)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_pred_array = y_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_pred_list = y_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot predictions versus training set outcomes\n",
    "plt.scatter(outcomes_list, y_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([-2, 4])\n",
    "\n",
    "axes.set_ylim([-2, 4])\n",
    "\n",
    "plt.plot([-2, 4], [-2, 4], 'k-', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the validation set predictions\n",
    "y_valid_pred = model(valid_predictors_Variable)\n",
    "\n",
    "\n",
    "# Print the loss\n",
    "loss_fn(y_valid_pred,\n",
    "        valid_outcomes_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_valid_pred_resized = y_valid_pred.resize(2748)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_valid_pred_array = y_valid_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_valid_pred_list = y_valid_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot new predictions versus new data outcomes\n",
    "plt.scatter(valid_outcomes_list, y_valid_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([-2, 4])\n",
    "\n",
    "axes.set_ylim([-2, 4])\n",
    "\n",
    "plt.plot([-2, 4], [-2, 4], 'k-', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the validation set predictions\n",
    "y_test_pred = model(test_predictors_Variable)\n",
    "\n",
    "\n",
    "# Print the loss\n",
    "loss_fn(y_test_pred,\n",
    "        test_outcomes_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_test_pred_resized = y_test_pred.resize(2699)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_test_pred_array = y_test_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Convert back to native units and scale\n",
    "y_test_pred_array = y_test_pred_array*5.41747 + 7.67485\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_test_pred_list = y_test_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot new predictions versus new data outcomes\n",
    "plt.scatter(test_outcomes_list, y_test_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([2, 23])\n",
    "\n",
    "axes.set_ylim([2, 23])\n",
    "\n",
    "axes.set_xticks([2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "axes.set_yticks([2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "plt.plot([2, 23], [2, 23], 'k-', lw=2)\n",
    "\n",
    "axes.set_xlabel(\"Actual Outcome (Log-Transformed US Dollars)\")\n",
    "\n",
    "axes.set_ylabel(\"Model Prediction (Log-Transformed US Dollars)\")\n",
    "\n",
    "axes.set_title(\"Model Performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: One Hundred Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the torch Tensor into a PyTorch Variable for dependent variables\n",
    "outcomes_Variable = Variable(outcomes_Tensor)\n",
    "\n",
    "\n",
    "# ...for independent variables\n",
    "features_Variable = Variable(features_Tensor,\n",
    "                             requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make the neural network\n",
    "model = torch.nn.Sequential(torch.nn.Linear(32, 32),    # Hidden Layer (HL) 1\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 2\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 3\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 4\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 5\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 6\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 7\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 8\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 9\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 10\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 11\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 12\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 13\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 14\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 15\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 16\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 17\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 18\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 19\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 20\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 21\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 22\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 23\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 24\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 25\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 26\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 27\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 28\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 29\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 30\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 31\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 32\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 33\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 34\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 35\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 36\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 37\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 38\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 39\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 40\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 41\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 42\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 43\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 44\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 45\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 46\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 47\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 48\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 49\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 50\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 51\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 52\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 53\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 54\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 55\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 56\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 57\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 58\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 59\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 60\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 61\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 62\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 63\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 64\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 65\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 66\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 67\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 68\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 69\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 70\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 71\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 72\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 73\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 74\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 75\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 76\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 77\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 78\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 79\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 80\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 81\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 82\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 83\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 84\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 85\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 86\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 87\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 88\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 89\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 90\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 91\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 92\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 93\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 94\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 95\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 96\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 97\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 98\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 99\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 32),    # HL 100\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To add errors to\n",
    "errors = []\n",
    "\n",
    "\n",
    "# Set the learning rate\n",
    "learning_rate = 2e-3\n",
    "\n",
    "\n",
    "# Define the model's optimizer\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "# Train the neural network\n",
    "for t in range(15000):\n",
    "    \n",
    "    # Get the current predictions\n",
    "    y_pred = model(features_Variable)\n",
    "    \n",
    "    # Compute and append current summed errors\n",
    "    loss = loss_fn(y_pred, outcomes_Variable)\n",
    "    errors.append(loss.data[0])\n",
    "    \n",
    "    # Zero the gradients before running the backward pass.\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable Variables\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the weights using Adagrad\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot summed error as a function of iteration\n",
    "plt.scatter(iterations, errors, c = \"black\", alpha = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_pred_resized = y_pred.resize(8230)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_pred_array = y_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_pred_list = y_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot predictions versus training set outcomes\n",
    "plt.scatter(outcomes_list, y_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([-2, 4])\n",
    "\n",
    "axes.set_ylim([-2, 4])\n",
    "\n",
    "plt.plot([-2, 4], [-2, 4], 'k-', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the validation set predictions\n",
    "y_valid_pred = model(valid_predictors_Variable)\n",
    "\n",
    "\n",
    "# Print the loss\n",
    "loss_fn(y_valid_pred,\n",
    "        valid_outcomes_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_valid_pred_resized = y_valid_pred.resize(2748)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_valid_pred_array = y_valid_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_valid_pred_list = y_valid_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot new predictions versus new data outcomes\n",
    "plt.scatter(valid_outcomes_list, y_valid_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([-2, 4])\n",
    "\n",
    "axes.set_ylim([-2, 4])\n",
    "\n",
    "plt.plot([-2, 4], [-2, 4], 'k-', lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the validation set predictions\n",
    "y_test_pred = model(test_predictors_Variable)\n",
    "\n",
    "\n",
    "# Print the loss\n",
    "loss_fn(y_test_pred,\n",
    "        test_outcomes_Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of the 2nd dimension of 1 from the FloatTensor\n",
    "y_test_pred_resized = y_test_pred.resize(2699)\n",
    "\n",
    "\n",
    "# Make the FloatTensor into a numpy.array\n",
    "y_test_pred_array = y_test_pred_resized.data.numpy()\n",
    "\n",
    "\n",
    "# Convert back to native units and scale\n",
    "y_test_pred_array = y_test_pred_array*5.41747 + 7.67485\n",
    "\n",
    "\n",
    "# Make the numpy.array into a list\n",
    "y_test_pred_list = y_test_pred_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot new predictions versus new data outcomes\n",
    "plt.scatter(test_outcomes_list, y_test_pred_list, c = \"black\", alpha = 0.15)\n",
    "\n",
    "axes = plt.gca()\n",
    "\n",
    "axes.set_xlim([2, 23])\n",
    "\n",
    "axes.set_ylim([2, 23])\n",
    "\n",
    "axes.set_xticks([2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "axes.set_yticks([2, 5, 8, 11, 14, 17, 20, 23])\n",
    "\n",
    "plt.plot([2, 23], [2, 23], 'k-', lw=2)\n",
    "\n",
    "axes.set_xlabel(\"Actual Outcome (Log-Transformed US Dollars)\")\n",
    "\n",
    "axes.set_ylabel(\"Model Prediction (Log-Transformed US Dollars)\")\n",
    "\n",
    "axes.set_title(\"Model Performance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
